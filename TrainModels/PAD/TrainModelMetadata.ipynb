{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNjTpwGL4VIfvskTbHWBez1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"cH0Sn906ILfM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702208058978,"user_tz":-120,"elapsed":28845,"user":{"displayName":"Θανάσης Πριμικύρης","userId":"14742434534342737133"}},"outputId":"267bcb71-fe3c-4639-d371-1a4c28d8483c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import zipfile, os, urllib.request, glob, math, shutil, sys, random\n","import torchvision\n","import torch.optim as optim\n","from torchvision import datasets, models, transforms\n","from sklearn.metrics import confusion_matrix, balanced_accuracy_score, precision_recall_fscore_support, roc_auc_score, accuracy_score\n","import sklearn.metrics\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","import PIL\n","import PIL.Image\n","\n","torch.manual_seed(0)\n","random.seed(9)\n","\n","sys.path.append('drive/MyDrive/TrainModels')\n","import modelArchs\n","\n","fold_number = 1\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","source":["\n","Οι εικόνες είναι αποθηκευμένες στο drive σε zip.\n","\n","Υπάρχουν 16 zip files, ένα για κάθε κλάση από το train και test dataset.\n","\n","Κάνω extract τις εικόνες.\n"],"metadata":{"id":"XtcfbzYZPk8r"}},{"cell_type":"code","source":["os.makedirs('train_imgs')\n","os.makedirs('test_imgs')\n","\n","prefix = 'drive/MyDrive/'\n","\n","for i in ['train_imgs', 'test_imgs']:\n","  for j in ['ACK', 'BCC', 'MEL', 'NEV', 'SCC', 'SEK']:\n","\n","    name = i + '_' + j\n","    src_zip = prefix + name + '.zip'\n","    dest_zip = i + '/' + j\n","\n","    with zipfile.ZipFile(src_zip, 'r') as zip_ref:\n","      zip_ref.extractall(dest_zip)\n","\n","    print(\"Finished with: \", name)"],"metadata":{"id":"NXUQKrYBITaN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702208115968,"user_tz":-120,"elapsed":56995,"user":{"displayName":"Θανάσης Πριμικύρης","userId":"14742434534342737133"}},"outputId":"39711984-5a83-4224-86cc-191fae4cad9b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Finished with:  train_imgs_ACK\n","Finished with:  train_imgs_BCC\n","Finished with:  train_imgs_MEL\n","Finished with:  train_imgs_NEV\n","Finished with:  train_imgs_SCC\n","Finished with:  train_imgs_SEK\n","Finished with:  test_imgs_ACK\n","Finished with:  test_imgs_BCC\n","Finished with:  test_imgs_MEL\n","Finished with:  test_imgs_NEV\n","Finished with:  test_imgs_SCC\n","Finished with:  test_imgs_SEK\n"]}]},{"cell_type":"markdown","source":["Κάνω load το μοντέλο που έγινε train χωρίς τα μετα-δεδομένα. Στη συνέχεια ορίζω το τελικό νευρωνικό δίκτυο(metaModel) που θα γίνει train στις εικόνες + μετα-δεδομένα."],"metadata":{"id":"37ejssCehxU9"}},{"cell_type":"code","source":["PATH = 'drive/MyDrive/mobilenet_sa_fold1.pt'\n","pretrained_model = modelArchs.get_MobileNetSa(6,False)\n","pretrained_model.load_state_dict(torch.load(PATH)['model'])\n","\n","metaModel = modelArchs.get_metaModel_MobileNets(pretrained_model,27,6, metaModelType = 1)\n","metaModel.to(device)"],"metadata":{"id":"m6Kvg6IfWBuu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Κάνω load τα metadata."],"metadata":{"id":"voDEMZNbS2bx"}},{"cell_type":"code","source":["#take into consideration this columns:\n","metadata_cols = ['img_id', 'age', 'region', 'itch', 'grew', 'hurt', 'changed', 'bleed', 'elevation', 'diagnostic', 'cancer_history', 'skin_cancer_history', 'gender']\n","features_list =  ['age', 'region', 'itch', 'grew', 'hurt', 'changed', 'bleed', 'elevation']\n","print(features_list)\n","\n","train_dataset = pd.read_csv('drive/MyDrive/g_train_dataset_app_Fold_' + str(fold_number) + '.csv')\n","test_dataset = pd.read_csv('drive/MyDrive/g_test_dataset_app_Fold_' + str(fold_number) + '.csv')\n","\n","for i in features_list:\n","  train_dataset[i] = train_dataset[i].apply(eval)\n","  test_dataset[i] = test_dataset[i].apply(eval)\n","\n","print(len(train_dataset))\n","print(len(test_dataset))\n","train_dataset.head()"],"metadata":{"id":"w5u-SZwHINQJ","colab":{"base_uri":"https://localhost:8080/","height":394},"executionInfo":{"status":"ok","timestamp":1702208134851,"user_tz":-120,"elapsed":1036,"user":{"displayName":"Θανάσης Πριμικύρης","userId":"14742434534342737133"}},"outputId":"06da5ae4-ca20-42f3-9c5b-21545cbb87fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['age', 'region', 'itch', 'grew', 'hurt', 'changed', 'bleed', 'elevation']\n","1787\n","511\n"]},{"output_type":"execute_result","data":{"text/plain":["  patient_id  lesion_id   smoke   drink                     background_father  \\\n","0   PAT_1516       1765  [1, 0]  [1, 0]  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]   \n","1     PAT_46        881  [1, 0]  [1, 0]  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]   \n","2   PAT_1545       1867  [1, 0]  [1, 0]  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]   \n","3   PAT_1989       4061  [1, 0]  [1, 0]  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]   \n","4    PAT_684       1302  [1, 0]  [0, 1]  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]   \n","\n","                background_mother                     age pesticide  gender  \\\n","0  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]   [-3.2599948193632113]    [0, 1]  [0, 1]   \n","1  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  [-0.34085429222456204]    [1, 0]  [1, 0]   \n","2  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]    [1.0255519119679972]    [0, 1]  [1, 0]   \n","3  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]    [0.9013331661323101]    [1, 0]  [1, 0]   \n","4  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]    [1.1497706578036844]    [1, 0]  [0, 1]   \n","\n","  skin_cancer_history  ...             diameter_2 diagnostic    itch    grew  \\\n","0              [1, 0]  ...                  [0.0]          3  [1, 0]  [1, 0]   \n","1              [0, 1]  ...  [-0.6584836774236833]          1  [0, 1]  [0, 1]   \n","2              [1, 0]  ...                  [0.0]          0  [0, 1]  [1, 0]   \n","3              [1, 0]  ...                  [0.0]          0  [0, 1]  [1, 0]   \n","4              [0, 1]  ...  [-0.6584836774236833]          1  [0, 1]  [0, 1]   \n","\n","     hurt changed   bleed  elevation                 img_id biopsed  \n","0  [1, 0]  [1, 0]  [1, 0]     [1, 0]  PAT_1516_1765_530.png   False  \n","1  [1, 0]  [0, 1]  [0, 1]     [0, 1]     PAT_46_881_939.png    True  \n","2  [1, 0]  [1, 0]  [1, 0]     [1, 0]  PAT_1545_1867_547.png   False  \n","3  [1, 0]  [1, 0]  [1, 0]     [1, 0]  PAT_1989_4061_934.png   False  \n","4  [1, 0]  [1, 0]  [0, 1]     [0, 1]   PAT_684_1302_588.png    True  \n","\n","[5 rows x 26 columns]"],"text/html":["\n","  <div id=\"df-4823c496-6f09-40f2-aa35-ab0ee3bc86cc\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>patient_id</th>\n","      <th>lesion_id</th>\n","      <th>smoke</th>\n","      <th>drink</th>\n","      <th>background_father</th>\n","      <th>background_mother</th>\n","      <th>age</th>\n","      <th>pesticide</th>\n","      <th>gender</th>\n","      <th>skin_cancer_history</th>\n","      <th>...</th>\n","      <th>diameter_2</th>\n","      <th>diagnostic</th>\n","      <th>itch</th>\n","      <th>grew</th>\n","      <th>hurt</th>\n","      <th>changed</th>\n","      <th>bleed</th>\n","      <th>elevation</th>\n","      <th>img_id</th>\n","      <th>biopsed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>PAT_1516</td>\n","      <td>1765</td>\n","      <td>[1, 0]</td>\n","      <td>[1, 0]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n","      <td>[-3.2599948193632113]</td>\n","      <td>[0, 1]</td>\n","      <td>[0, 1]</td>\n","      <td>[1, 0]</td>\n","      <td>...</td>\n","      <td>[0.0]</td>\n","      <td>3</td>\n","      <td>[1, 0]</td>\n","      <td>[1, 0]</td>\n","      <td>[1, 0]</td>\n","      <td>[1, 0]</td>\n","      <td>[1, 0]</td>\n","      <td>[1, 0]</td>\n","      <td>PAT_1516_1765_530.png</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>PAT_46</td>\n","      <td>881</td>\n","      <td>[1, 0]</td>\n","      <td>[1, 0]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n","      <td>[-0.34085429222456204]</td>\n","      <td>[1, 0]</td>\n","      <td>[1, 0]</td>\n","      <td>[0, 1]</td>\n","      <td>...</td>\n","      <td>[-0.6584836774236833]</td>\n","      <td>1</td>\n","      <td>[0, 1]</td>\n","      <td>[0, 1]</td>\n","      <td>[1, 0]</td>\n","      <td>[0, 1]</td>\n","      <td>[0, 1]</td>\n","      <td>[0, 1]</td>\n","      <td>PAT_46_881_939.png</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>PAT_1545</td>\n","      <td>1867</td>\n","      <td>[1, 0]</td>\n","      <td>[1, 0]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n","      <td>[1.0255519119679972]</td>\n","      <td>[0, 1]</td>\n","      <td>[1, 0]</td>\n","      <td>[1, 0]</td>\n","      <td>...</td>\n","      <td>[0.0]</td>\n","      <td>0</td>\n","      <td>[0, 1]</td>\n","      <td>[1, 0]</td>\n","      <td>[1, 0]</td>\n","      <td>[1, 0]</td>\n","      <td>[1, 0]</td>\n","      <td>[1, 0]</td>\n","      <td>PAT_1545_1867_547.png</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>PAT_1989</td>\n","      <td>4061</td>\n","      <td>[1, 0]</td>\n","      <td>[1, 0]</td>\n","      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n","      <td>[0.9013331661323101]</td>\n","      <td>[1, 0]</td>\n","      <td>[1, 0]</td>\n","      <td>[1, 0]</td>\n","      <td>...</td>\n","      <td>[0.0]</td>\n","      <td>0</td>\n","      <td>[0, 1]</td>\n","      <td>[1, 0]</td>\n","      <td>[1, 0]</td>\n","      <td>[1, 0]</td>\n","      <td>[1, 0]</td>\n","      <td>[1, 0]</td>\n","      <td>PAT_1989_4061_934.png</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>PAT_684</td>\n","      <td>1302</td>\n","      <td>[1, 0]</td>\n","      <td>[0, 1]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n","      <td>[1.1497706578036844]</td>\n","      <td>[1, 0]</td>\n","      <td>[0, 1]</td>\n","      <td>[0, 1]</td>\n","      <td>...</td>\n","      <td>[-0.6584836774236833]</td>\n","      <td>1</td>\n","      <td>[0, 1]</td>\n","      <td>[0, 1]</td>\n","      <td>[1, 0]</td>\n","      <td>[1, 0]</td>\n","      <td>[0, 1]</td>\n","      <td>[0, 1]</td>\n","      <td>PAT_684_1302_588.png</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 26 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4823c496-6f09-40f2-aa35-ab0ee3bc86cc')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-4823c496-6f09-40f2-aa35-ab0ee3bc86cc button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-4823c496-6f09-40f2-aa35-ab0ee3bc86cc');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-736fc101-8ac5-4db2-9123-b181913bb660\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-736fc101-8ac5-4db2-9123-b181913bb660')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-736fc101-8ac5-4db2-9123-b181913bb660 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["Ορίζω διάφορα transformations για να κάνουμε augment το training set, ώστε να πετύχουμε καλύτερο generalization του μοντέλου."],"metadata":{"id":"LjOqcyGAaLSc"}},{"cell_type":"code","source":["transforms_train = transforms.Compose([\n","    transforms.RandomResizedCrop(size = 224, scale = (0.4,1.0)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomVerticalFlip(),\n","    transforms.ColorJitter(brightness = [0.7, 1.3], contrast = [0.7, 1.3], saturation = [0.7, 1.3], hue = [-0.1,0.1]),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","transforms_test = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])"],"metadata":{"id":"kZHAX1eJYPxJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ορισμός υπερ-παραμέτρων."],"metadata":{"id":"MVsLdTGnYepU"}},{"cell_type":"code","source":["epochs = 30\n","batch_len = 32\n","\n","criterion = nn.CrossEntropyLoss()\n","learning_rate = 0.001\n","optimizer = optim.Adam(metaModel.parameters(), lr=learning_rate)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma=0.2)"],"metadata":{"id":"AQKzxrWEYeQZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Υλοποιώ το δικό μου dataset, καθώς θα θέλαμε, εκτός από την εικόνα, να γίνονται load και τα αντίστοιχα metadata."],"metadata":{"id":"Hqz80pxgcm9u"}},{"cell_type":"code","source":["class ImageFolderWithFileNames(datasets.ImageFolder):\n","\n","    def __init__(self, root_dir, train_transformations, current_dataset, features_list):\n","\n","      super().__init__(root_dir,train_transformations)\n","\n","      self.current_dataset = current_dataset\n","      self.features_list = features_list\n","\n","    def __getitem__(self, index):\n","\n","      path, target = self.imgs[index]\n","\n","      filename = path[path.rfind('/') + 1:]\n","      metadata_features = self.get_metadata_features(filename)\n","\n","      img = self.loader(path)\n","\n","      if self.transform is not None:\n","        img = self.transform(img)\n","      if self.target_transform is not None:\n","        target = self.target_transform(target)\n","\n","      return metadata_features,img,target\n","\n","    def get_metadata_features(self,filename):\n","\n","      features = []\n","\n","      index_row = self.current_dataset.index[self.current_dataset['img_id'] == filename].tolist()[0]#get index of the row that corresponds to the image\n","      feature_cols = self.current_dataset.iloc[index_row][self.features_list].to_numpy().flatten()\n","\n","      for i in feature_cols:\n","        for j in i:\n","          features.append(j)\n","\n","      return torch.tensor(features)"],"metadata":{"id":"meGlatl102sk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ορίζουμε weights για κάθε κλάση, ώστε να αντιμετωπίσουμε το πρόβλημα του imbalanced dataset."],"metadata":{"id":"TAmFmXCeaBUD"}},{"cell_type":"code","source":["def get_weights_for_imgs(images, n_categories):\n","\n","    n_images = len(images)\n","\n","    imgs_per_category = [0] * n_categories\n","    for _, image_category in images:\n","      imgs_per_category[image_category] += 1\n","\n","    weight_per_category = [0] * n_categories # έχουμε 6 κατηγορίες\n","    for i in range(n_categories):\n","      weight_per_category[i] = 1 / float(imgs_per_category[i])#float(n_images) / float(imgs_per_category[i])\n","\n","    weights = [0] * n_images\n","    for idx, (_, image_category) in enumerate(images):\n","        weights[idx] = weight_per_category[image_category]\n","\n","    return weights\n","\n","train_dataset_imgs = ImageFolderWithFileNames('train_imgs', transforms_train, train_dataset, features_list)\n","test_dataset_imgs = ImageFolderWithFileNames('test_imgs', transforms_test, test_dataset, features_list)\n","\n","len_train_dataset_imgs = len(train_dataset_imgs)\n","len_test_dataset_imgs = len(test_dataset_imgs)\n","\n","print(\"Length of train_dataset: \", len_train_dataset_imgs)\n","print(\"Length of test dataset: \", len_test_dataset_imgs)\n","\n","weights = get_weights_for_imgs(train_dataset_imgs.imgs, len(train_dataset_imgs.classes))\n","weights = torch.DoubleTensor(weights)\n","train_sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))\n","\n","train_dataloader_imgs = torch.utils.data.DataLoader(train_dataset_imgs, batch_size = batch_len, sampler = train_sampler, pin_memory=True)\n","test_dataloader_imgs = torch.utils.data.DataLoader(test_dataset_imgs, batch_size = 8, shuffle=False)"],"metadata":{"id":"3KKuq3CqaAg4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702208147884,"user_tz":-120,"elapsed":364,"user":{"displayName":"Θανάσης Πριμικύρης","userId":"14742434534342737133"}},"outputId":"97eaf419-9784-4bf8-94e4-0091ac564954"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Length of train_dataset:  1787\n","Length of test dataset:  511\n"]}]},{"cell_type":"markdown","source":["Ορίζω συναρτήσεις για υπολογισμό του accuracy και του confusion matrix πάνω στο test set. Στη συνέχεια θα δημιουργήσω και άλλες συναρτήσεις για υπολογισμό F1-score, sensitivity, specificity, precision."],"metadata":{"id":"YOGTsTk2z36g"}},{"cell_type":"code","source":["def test_model(model,test_dataloader):\n","\n","  pred_list = []\n","  label_list = []\n","  output_probs = []\n","  metrics = []\n","\n","  for i, (metadata_features, imgs, labels) in enumerate(test_dataloader,1):\n","\n","    label_list.extend(labels.data.tolist())\n","\n","    metadata_features = metadata_features.to(device)\n","    imgs = imgs.to(device)\n","    labels = labels.to(device)\n","\n","    outputs = model(metadata_features,imgs)\n","\n","    probs = torch.softmax(outputs.data.cpu(), dim = 1).tolist()\n","    output_probs.extend(probs)\n","\n","    pred =  torch.max(outputs, 1)[1].data.cpu().tolist()\n","    pred_list.extend(pred)\n","\n","  conf_matrix = confusion_matrix(label_list , pred_list)\n","\n","  metrics.append(accuracy_score(label_list, pred_list))\n","  metrics.extend(precision_recall_fscore_support(label_list,pred_list, average = 'macro'))\n","  metrics.append(roc_auc_score(label_list,output_probs, average = 'macro', multi_class = 'ovr'))\n","  metrics.extend(precision_recall_fscore_support(label_list,pred_list, average = 'weighted'))\n","  metrics.append(roc_auc_score(label_list,output_probs, average = 'weighted', multi_class = 'ovr'))\n","\n","  return metrics, conf_matrix"],"metadata":{"id":"r4DJv0WNz3P8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Το βασικό train loop."],"metadata":{"id":"LdOi3h4ej5oX"}},{"cell_type":"code","source":["for epoch in range(1, epochs + 1):\n","\n","  metaModel.train()\n","\n","  train_running_loss = 0\n","\n","  #Training phase\n","  print(\"Starting epoch: \" , epoch)\n","\n","  for i, (metadata_features, imgs, labels) in enumerate(train_dataloader_imgs,1):\n","\n","      metadata_features = metadata_features.to(device)\n","      imgs = imgs.to(device)\n","      labels = labels.to(device)\n","\n","      optimizer.zero_grad()\n","      outputs = metaModel(metadata_features,imgs)\n","      loss = criterion(outputs, labels)\n","      loss.backward()\n","      optimizer.step()\n","\n","      train_running_loss += loss.detach().item()\n","\n","  print('Epoch: %d | Loss: %.4f ' %(epoch, train_running_loss / i))\n","  scheduler.step()\n","\n","  metaModel.eval()\n","\n","  try:\n","    metrics,conf_matrix = test_model(metaModel,test_dataloader_imgs)\n","    print('Test metrics on epoch %d:' %(epoch))\n","    print(metrics)\n","    print(\"Confusion matrix: \")\n","    print(conf_matrix)\n","  except:\n","    print(\"Error in calculating metrics\")\n","\n","  try:\n","    checkpoint = {'model': metaModel.state_dict()}\n","    checkpoint_fn = 'drive/MyDrive/checkpoint' + str(epoch) + '.pt'\n","    torch.save(checkpoint, checkpoint_fn)\n","  except:\n","    print(\"Error in writing general checkpoint\")"],"metadata":{"id":"zdOoTlq0c02k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Τεστ για filenames."],"metadata":{"id":"oeQCREGw8DNb"}},{"cell_type":"code","source":["import collections\n","\n","for i, (meta_features,inputs, labels) in enumerate(train_dataloader_imgs,1):\n","\n","  print(\"Metadata shape:\")\n","  print(meta_features.shape)\n","  print(\"Labels shape:\")\n","  print(collections.Counter(labels.tolist()))\n","  print(\"Inputs shape\")\n","  print(inputs.shape)\n","  break"],"metadata":{"id":"n_DZxUFmvKhB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702208349981,"user_tz":-120,"elapsed":2412,"user":{"displayName":"Θανάσης Πριμικύρης","userId":"14742434534342737133"}},"outputId":"2c8df64a-e258-4365-e4bb-a0f7fdf2a626"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Metadata shape:\n","torch.Size([32, 27])\n","Labels shape:\n","Counter({1: 7, 4: 6, 5: 6, 2: 6, 3: 5, 0: 2})\n","Inputs shape\n","torch.Size([32, 3, 224, 224])\n"]}]}]}