{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP76Pmqi2yWJcqtnXBCfn7U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"cH0Sn906ILfM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695633354582,"user_tz":-180,"elapsed":24636,"user":{"displayName":"Θανάσης Πριμικύρης","userId":"14742434534342737133"}},"outputId":"409f5f98-7a24-4b3b-db02-66ba92a3dd28"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import zipfile, os, urllib.request, glob, math, shutil, sys, random\n","import torchvision\n","import torch.optim as optim\n","from torchvision import datasets, models, transforms\n","from sklearn.metrics import confusion_matrix, balanced_accuracy_score, precision_recall_fscore_support, roc_auc_score, accuracy_score\n","import sklearn.metrics\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","import PIL\n","import PIL.Image\n","\n","torch.manual_seed(0)\n","random.seed(9)\n","\n","sys.path.append('drive/MyDrive')\n","import modelArchs\n","\n","fold_number = 1\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","source":["\n","Οι εικόνες είναι αποθηκευμένες στο drive σε zip.\n","\n","Υπάρχουν 16 zip files, ένα για κάθε κλάση από το train και test dataset.\n","\n","Κάνω extract τις εικόνες.\n"],"metadata":{"id":"XtcfbzYZPk8r"}},{"cell_type":"code","source":["os.makedirs('train_imgs')\n","os.makedirs('test_imgs')\n","\n","prefix = 'drive/MyDrive/'\n","\n","for i in ['train_imgs', 'test_imgs']:\n","  for j in ['ACK', 'BCC', 'MEL', 'NEV', 'SCC', 'SEK']:\n","\n","    name = i + '_' + j\n","    src_zip = prefix + name + '.zip'\n","    dest_zip = i + '/' + j\n","\n","    with zipfile.ZipFile(src_zip, 'r') as zip_ref:\n","      zip_ref.extractall(dest_zip)\n","\n","    print(\"Finished with: \", name)"],"metadata":{"id":"NXUQKrYBITaN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Κάνω load το μοντέλο που έγινε train χωρίς τα μετα-δεδομένα. Στη συνέχεια ορίζω το τελικό νευρωνικό δίκτυο(metaModel) που θα γίνει train στις εικόνες + μετα-δεδομένα."],"metadata":{"id":"37ejssCehxU9"}},{"cell_type":"code","source":["PATH = 'drive/MyDrive/mobilenet_sa_fold1.pt'\n","pretrained_model = modelArchs.get_MobileNetSa(6,False)\n","pretrained_model.load_state_dict(torch.load(PATH)['model'])\n","\n","metaModel = modelArchs.get_metaModel_MobileNets(pretrained_model,27,6)\n","metaModel.to(device)"],"metadata":{"id":"m6Kvg6IfWBuu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Κάνω load τα metadata."],"metadata":{"id":"voDEMZNbS2bx"}},{"cell_type":"code","source":["#take into consideration this columns:\n","metadata_cols = ['img_id', 'age', 'region', 'itch', 'grew', 'hurt', 'changed', 'bleed', 'elevation', 'diagnostic', 'cancer_history', 'skin_cancer_history', 'gender']\n","features_list =  ['age', 'region', 'itch', 'grew', 'hurt', 'changed', 'bleed', 'elevation']\n","print(features_list)\n","\n","train_dataset = pd.read_csv('drive/MyDrive/train_dataset_app_Fold_' + str(fold_number) + '.csv')\n","test_dataset = pd.read_csv('drive/MyDrive/test_dataset_app_Fold_' + str(fold_number) + '.csv')\n","\n","for i in features_list:\n","  train_dataset[i] = train_dataset[i].apply(eval)\n","  test_dataset[i] = test_dataset[i].apply(eval)\n","\n","print(len(train_dataset))\n","print(len(test_dataset))\n","train_dataset.head()"],"metadata":{"id":"w5u-SZwHINQJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ορίζω διάφορα transformations για να κάνουμε augment το training set, ώστε να πετύχουμε καλύτερο generalization του μοντέλου."],"metadata":{"id":"LjOqcyGAaLSc"}},{"cell_type":"code","source":["transforms_train = transforms.Compose([\n","    transforms.RandomResizedCrop(size = 224, scale = (0.4,1.0)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomVerticalFlip(),\n","    transforms.ColorJitter(brightness = [0.7, 1.3], contrast = [0.7, 1.3], saturation = [0.7, 1.3], hue = [-0.1,0.1]),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","transforms_test = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])"],"metadata":{"id":"kZHAX1eJYPxJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ορισμός υπερ-παραμέτρων."],"metadata":{"id":"MVsLdTGnYepU"}},{"cell_type":"code","source":["epochs = 30\n","batch_len = 48\n","\n","criterion = nn.CrossEntropyLoss()\n","learning_rate = 0.001\n","optimizer = optim.Adam(metaModel.parameters(), lr=learning_rate)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma=0.2)"],"metadata":{"id":"AQKzxrWEYeQZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Υλοποιώ το δικό μου dataset, καθώς θα θέλαμε, εκτός από την εικόνα, να γίνονται load και τα αντίστοιχα metadata."],"metadata":{"id":"Hqz80pxgcm9u"}},{"cell_type":"code","source":["class ImageFolderWithFileNames(datasets.ImageFolder):\n","\n","    def __init__(self, root_dir, train_transformations, current_dataset, features_list):\n","\n","      super().__init__(root_dir,train_transformations)\n","\n","      self.current_dataset = current_dataset\n","      self.features_list = features_list\n","\n","    def __getitem__(self, index):\n","\n","      path, target = self.imgs[index]\n","\n","      filename = path[path.rfind('/') + 1:]\n","      metadata_features = self.get_metadata_features(filename)\n","\n","      img = self.loader(path)\n","\n","      if self.transform is not None:\n","        img = self.transform(img)\n","      if self.target_transform is not None:\n","        target = self.target_transform(target)\n","\n","      return metadata_features,img,target\n","\n","    def get_metadata_features(self,filename):\n","\n","      features = []\n","\n","      index_row = self.current_dataset.index[self.current_dataset['img_id'] == filename].tolist()[0]#get index of the row that corresponds to the image\n","      feature_cols = self.current_dataset.iloc[index_row][self.features_list].to_numpy().flatten()\n","\n","      for i in feature_cols:\n","        for j in i:\n","          features.append(j)\n","\n","      return torch.tensor(features)"],"metadata":{"id":"meGlatl102sk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ορίζουμε weights για κάθε κλάση, ώστε να αντιμετωπίσουμε το πρόβλημα του imbalanced dataset."],"metadata":{"id":"TAmFmXCeaBUD"}},{"cell_type":"code","source":["def get_weights_for_imgs(images, n_categories):\n","\n","    n_images = len(images)\n","\n","    imgs_per_category = [0] * n_categories\n","    for _, image_category in images:\n","      imgs_per_category[image_category] += 1\n","\n","    weight_per_category = [0] * n_categories # έχουμε 6 κατηγορίες\n","    for i in range(n_categories):\n","      weight_per_category[i] = 1 / float(imgs_per_category[i])#float(n_images) / float(imgs_per_category[i])\n","\n","    weights = [0] * n_images\n","    for idx, (_, image_category) in enumerate(images):\n","        weights[idx] = weight_per_category[image_category]\n","\n","    return weights\n","\n","train_dataset_imgs = ImageFolderWithFileNames('train_imgs', transforms_train, train_dataset, features_list)\n","test_dataset_imgs = ImageFolderWithFileNames('test_imgs', transforms_test, test_dataset, features_list)\n","\n","len_train_dataset_imgs = len(train_dataset_imgs)\n","len_test_dataset_imgs = len(test_dataset_imgs)\n","\n","print(\"Length of train_dataset: \", len_train_dataset_imgs)\n","print(\"Length of test dataset: \", len_test_dataset_imgs)\n","\n","weights = get_weights_for_imgs(train_dataset_imgs.imgs, len(train_dataset_imgs.classes))\n","weights = torch.DoubleTensor(weights)\n","train_sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))\n","\n","train_dataloader_imgs = torch.utils.data.DataLoader(train_dataset_imgs, batch_size = batch_len, sampler = train_sampler, pin_memory=True)\n","test_dataloader_imgs = torch.utils.data.DataLoader(test_dataset_imgs, batch_size = 8, shuffle=False)"],"metadata":{"id":"3KKuq3CqaAg4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695476066701,"user_tz":-180,"elapsed":25,"user":{"displayName":"Θανάσης Πριμικύρης","userId":"14742434534342737133"}},"outputId":"5297ba7a-cd9b-4e53-caae-3ff1ca9f3dd6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Length of train_dataset:  1787\n","Length of test dataset:  511\n"]}]},{"cell_type":"markdown","source":["Ορίζω συναρτήσεις για υπολογισμό του accuracy και του confusion matrix πάνω στο test set. Στη συνέχεια θα δημιουργήσω και άλλες συναρτήσεις για υπολογισμό F1-score, sensitivity, specificity, precision."],"metadata":{"id":"YOGTsTk2z36g"}},{"cell_type":"code","source":["def test_model(model,test_dataloader):\n","\n","  pred_list = []\n","  label_list = []\n","  output_probs = []\n","  metrics = []\n","\n","  for i, (metadata_features, imgs, labels) in enumerate(test_dataloader,1):\n","\n","    label_list.extend(labels.data.tolist())\n","\n","    metadata_features = metadata_features.to(device)\n","    imgs = imgs.to(device)\n","    labels = labels.to(device)\n","\n","    outputs = model(metadata_features,imgs)\n","\n","    probs = torch.softmax(outputs.data.cpu(), dim = 1).tolist()\n","    output_probs.extend(probs)\n","\n","    pred =  torch.max(outputs, 1)[1].data.cpu().tolist()\n","    pred_list.extend(pred)\n","\n","  conf_matrix = confusion_matrix(label_list , pred_list)\n","\n","  metrics.append(accuracy_score(label_list, pred_list))\n","  metrics.extend(precision_recall_fscore_support(label_list,pred_list, average = 'macro'))\n","  metrics.append(roc_auc_score(label_list,output_probs, average = 'macro', multi_class = 'ovr'))\n","  metrics.extend(precision_recall_fscore_support(label_list,pred_list, average = 'weighted'))\n","  metrics.append(roc_auc_score(label_list,output_probs, average = 'weighted', multi_class = 'ovr'))\n","\n","  return metrics, conf_matrix"],"metadata":{"id":"r4DJv0WNz3P8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Το βασικό train loop."],"metadata":{"id":"LdOi3h4ej5oX"}},{"cell_type":"code","source":["for epoch in range(1, epochs + 1):\n","\n","  metaModel.train()\n","\n","  train_running_loss = 0\n","\n","  #Training phase\n","  print(\"Starting epoch: \" , epoch)\n","\n","  for i, (metadata_features, imgs, labels) in enumerate(train_dataloader_imgs,1):\n","\n","      metadata_features = metadata_features.to(device)\n","      imgs = imgs.to(device)\n","      labels = labels.to(device)\n","\n","      optimizer.zero_grad()\n","      outputs = metaModel(metadata_features,imgs)\n","      loss = criterion(outputs, labels)\n","      loss.backward()\n","      optimizer.step()\n","\n","      train_running_loss += loss.detach().item()\n","\n","  print('Epoch: %d | Loss: %.4f ' %(epoch, train_running_loss / i))\n","  scheduler.step()\n","\n","  metaModel.eval()\n","\n","  try:\n","    metrics,conf_matrix = test_model(metaModel,test_dataloader_imgs)\n","    print('Test metrics on epoch %d:' %(epoch))\n","    print(metrics)\n","    print(\"Confusion matrix: \")\n","    print(conf_matrix)\n","  except:\n","    print(\"Error in calculating metrics\")\n","\n","  try:\n","    checkpoint = {'model': metaModel.state_dict()}\n","    checkpoint_fn = 'drive/MyDrive/checkpoint' + str(epoch) + '.pt'\n","    torch.save(checkpoint, checkpoint_fn)\n","  except:\n","    print(\"Error in writing general checkpoint\")"],"metadata":{"id":"zdOoTlq0c02k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Τεστ για filenames."],"metadata":{"id":"oeQCREGw8DNb"}},{"cell_type":"code","source":["for i, (meta_features,inputs, labels) in enumerate(train_dataloader_imgs,1):\n","\n","  print(\"Metadata shape:\")\n","  print(meta_features.shape)\n","  print(\"Labels shape:\")\n","  print(labels)\n","  print(\"Inputs shape\")\n","  print(inputs.shape)\n","  break"],"metadata":{"id":"n_DZxUFmvKhB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694816767660,"user_tz":-180,"elapsed":2860,"user":{"displayName":"Θανάσης Πριμικύρης","userId":"14742434534342737133"}},"outputId":"afb14b56-d5a4-4573-b999-ce2b72de6312"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Metadata shape:\n","torch.Size([48, 33])\n","Labels shape:\n","tensor([0, 3, 4, 4, 0, 3, 0, 2, 2, 1, 0, 4, 4, 2, 5, 3, 4, 1, 4, 3, 0, 4, 1, 4,\n","        2, 4, 2, 3, 0, 5, 3, 1, 1, 2, 4, 4, 2, 4, 3, 2, 2, 4, 1, 4, 0, 3, 1, 1])\n","Inputs shape\n","torch.Size([48, 3, 224, 224])\n"]}]}]}