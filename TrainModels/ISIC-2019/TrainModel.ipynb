{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"KJtTRPP9f5Tk"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import zipfile, os, urllib.request, glob, math, shutil, sys\n","import torchvision\n","import torch.optim as optim\n","from torchvision import datasets, models, transforms\n","from sklearn.metrics import confusion_matrix, balanced_accuracy_score, precision_recall_fscore_support, roc_auc_score, accuracy_score\n","import sklearn.metrics\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","import PIL\n","import PIL.Image\n","\n","sys.path.append('drive/MyDrive')\n","import modelArchs\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","resume = 0"]},{"cell_type":"markdown","metadata":{"id":"UUYPCU7Rk2Xa"},"source":["Οι εικόνες είναι αποθηκευμένες στο drive σε zip.\n","\n","Υπάρχουν 16 zip files, ένα για κάθε κλάση από το train και test dataset.\n","\n","Κάνω extract τις εικόνες."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WbiX3oAFk1_l"},"outputs":[],"source":["os.makedirs('train_imgs')\n","os.makedirs('val_imgs')\n","\n","prefix = 'drive/MyDrive/'\n","\n","for i in ['train_imgs', 'val_imgs']:\n","  for j in ['MEL','NV','BCC','AK','BKL','DF','VASC','SCC']:\n","\n","    name = i + '_' + j\n","    src_zip = prefix + name + '.zip'\n","    dest_zip = i + '/' + j\n","\n","    with zipfile.ZipFile(src_zip, 'r') as zip_ref:\n","      zip_ref.extractall(dest_zip)\n","\n","    print(\"Finished with: \", name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ghaSFxpVjRUV"},"outputs":[],"source":["val_dataset = pd.read_csv('drive/MyDrive/val_dataset.csv')\n","train_dataset = pd.read_csv('drive/MyDrive/train_dataset.csv')\n","train_dataset.head()"]},{"cell_type":"markdown","metadata":{"id":"2pHjHejrrIQc"},"source":["Κάνω load τα pretrained μοντέλα trained πάνω στο imagenet. Στο τελευταίο layer αλλάζουμε τα out_features σε 8, καθώς έχουμε 8 διαφορετικές κλάσεις προς ταξινόμηση."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NdH26FZUhPfH"},"outputs":[],"source":["#model = modelArchs.get_EfficientNet(8,True)\n","#model = modelArchs.get_GoogleNet(8,True)\n","#model = modelArchs.get_MobileNet(8,True)\n","#model = modelArchs.get_Resnet(8,True)\n","model = modelArchs.get_MobileNetSa(8,True)\n","model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"HzbXvAprzVQb"},"source":["Ορίζω διάφορα transformations ώστε να κάνουμε augment το training set, ώστε να πετύχουμε καλύτερο generalization του μοντέλου."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k5eLDqnsUnbT"},"outputs":[],"source":["transforms_train = transforms.Compose([\n","    transforms.RandomResizedCrop(size = 224, scale = (0.4,1.0)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomVerticalFlip(),\n","    transforms.ColorJitter(brightness = [0.7, 1.3], contrast = [0.7, 1.3], saturation = [0.7, 1.3], hue = [-0.1,0.1]),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","transforms_val = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])"]},{"cell_type":"markdown","metadata":{"id":"BCVMC5dcy-6y"},"source":["Ορισμός υπερ-παραμέτρων\n","\n","Load προηγούμενο checkpoint."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8bJZU1VvSNTO"},"outputs":[],"source":["epochs = 30\n","batch_len = 48\n","\n","criterion = nn.CrossEntropyLoss()\n","learning_rate = 0.001\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma=0.2)\n","\n","if resume:\n","  checkpoint = torch.load('drive/MyDrive/checkpoint6.pt')\n","  model.load_state_dict(checkpoint['model'])\n","  optimizer.load_state_dict(checkpoint['optimizer'])\n","  scheduler.load_state_dict(checkpoint['scheduler'])\n","  epoch_count = checkpoint['epoch']\n","  print(scheduler.get_last_lr())\n","else:\n","  epoch_count = 1\n","\n","print(epoch_count)"]},{"cell_type":"markdown","metadata":{"id":"GTmoUV2C0Bnv"},"source":["Εδώ ορίζω τα dataset και dataloaders, χρησιμοποιώντας το weightRandomSampler για να δημιουργήσει balanced batches:\n","\n","https://towardsdatascience.com/demystifying-pytorchs-weightedrandomsampler-by-example-a68aceccb452"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KaBG7AOYemTw"},"outputs":[],"source":["def get_weights_for_imgs(images, n_categories):\n","\n","    n_images = len(images)\n","\n","    #εδώ θα μπορούσα να χρησιμοποιήσω έτοιμους τους αριθμούς images per class από το train_dataset.category.value_counts() , ωστόσο στην συνέχεια όταν κάνω enumerate(images) στην\n","    #τελευταία for, αυτό μπορεί να δημιουργήσει πρόβλημα, καθώς δεν ξέρουμε το image_category σε ποιό label πραγματικά αντιστοιχεί...\n","    imgs_per_category = [0] * n_categories\n","    for _, image_category in images:\n","      imgs_per_category[image_category] += 1\n","\n","    weight_per_category = [0] * n_categories # έχουμε 8 κατηγορίες\n","    for i in range(n_categories):\n","      weight_per_category[i] = 1 / float(imgs_per_category[i])#float(n_images) / float(imgs_per_category[i])\n","\n","    weights = [0] * n_images\n","    for idx, (_, image_category) in enumerate(images):\n","        weights[idx] = weight_per_category[image_category]\n","\n","    return weights\n","\n","train_dataset = datasets.ImageFolder('train_imgs', transforms_train)\n","val_dataset = datasets.ImageFolder('val_imgs', transforms_val)\n","\n","len_train_dataset = len(train_dataset)\n","len_val_dataset = len(val_dataset)\n","\n","print(\"Length of train_dataset: \", len_train_dataset)\n","print(\"Length of val dataset: \", len_val_dataset)\n","\n","weights = get_weights_for_imgs(train_dataset.imgs, len(train_dataset.classes))\n","weights = torch.DoubleTensor(weights)\n","train_sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))\n","\n","train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_len, sampler = train_sampler, pin_memory=True)\n","val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size = 16, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"UBH_lDTr0n2S"},"source":["Ορίζω συναρτήσεις για υπολογισμό του accuracy και του confusion matrix πάνω στο test set. Στη συνέχεια θα δημιουργήσω και άλλες συναρτήσεις για υπολογισμό F1-score, sensitivity, specificity, precision."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F-nQYTLfkJVO"},"outputs":[],"source":["def test_model(model,test_dataloader):\n","\n","  test_acc = 0.0\n","  pred_list = []\n","  label_list = []\n","  output_probs = []\n","  metrics = []\n","\n","  for i, (inputs, labels) in enumerate(test_dataloader,1):\n","\n","    label_list.extend(labels.detach().tolist())\n","\n","    inputs = inputs.to(device)\n","    labels = labels.to(device)\n","    outputs = model(inputs)\n","    probs = torch.softmax(outputs.detach().cpu(), dim = 1).tolist()\n","    output_probs.extend(probs)\n","\n","    pred =  torch.max(outputs, 1)[1].detach().cpu().tolist()\n","    pred_list.extend(pred)\n","\n","  conf_matrix = confusion_matrix(label_list , pred_list)\n","\n","  metrics.append(accuracy_score(label_list, pred_list))\n","  metrics.extend(precision_recall_fscore_support(label_list,pred_list, average = 'macro'))\n","  metrics.append(roc_auc_score(label_list,output_probs, average = 'macro', multi_class = 'ovr'))\n","  metrics.extend(precision_recall_fscore_support(label_list,pred_list, average = 'weighted'))\n","  metrics.append(roc_auc_score(label_list,output_probs, average = 'weighted', multi_class = 'ovr'))\n","\n","  return metrics, conf_matrix"]},{"cell_type":"markdown","metadata":{"id":"x2F_rAr91Q15"},"source":["Το βασικό train loop."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WS21NFFAg0L5"},"outputs":[],"source":["for epoch in range(epoch_count, epochs + 1):\n","\n","  model.train()\n","  train_running_loss = 0\n","\n","  print(\"Starting epoch: \" , epoch)\n","\n","  for i, (inputs, labels) in enumerate(train_dataloader,1):\n","      inputs = inputs.to(device)\n","      labels = labels.to(device)\n","\n","      optimizer.zero_grad()\n","      outputs = model(inputs)\n","      loss = criterion(outputs, labels)\n","      loss.backward()\n","      optimizer.step()\n","\n","      train_running_loss += loss.detach().item()\n","\n","      if i % 100 == 0:\n","        print(\"Batch number: %d\" %(i))\n","\n","  print('Epoch: %d | Loss: %.4f ' %(epoch, train_running_loss / i))\n","  scheduler.step()\n","\n","  model.eval()\n","  try:\n","    metrics,conf_matrix = test_model(model,val_dataloader)\n","    print(\"Metrics on epoch %d: \" %epoch)\n","    print(metrics)\n","    print(\"Confusion matrix:\")\n","    print(conf_matrix)\n","  except:\n","    print(\"Error in calculating metrics\")\n","\n","  try:\n","    checkpoint = {'epoch': epoch+1, 'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'scheduler': scheduler.state_dict()}\n","    checkpoint_fn = 'drive/MyDrive/checkpoint' + str(epoch) + '.pt'\n","    torch.save(checkpoint, checkpoint_fn)\n","  except:\n","    print(\"Error in writing general checkpoint\")\n","  if epoch - epoch_count >= 5:\n","    break"]},{"cell_type":"markdown","metadata":{"id":"llb_WIdtyv_2"},"source":["Το επόμενο cell είναι για έλεγχο των διαστάσεων input, output και της κατανομής των κλάσεων μέσα σε ένα batch."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2588,"status":"ok","timestamp":1689452429169,"user":{"displayName":"Θανάσης Πριμικύρης","userId":"14742434534342737133"},"user_tz":-180},"id":"2FPJHN8lqwYn","outputId":"f2d89ebd-fb62-4d0f-dd72-677337a94a5f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input size: torch.Size([64, 3, 224, 224])\n","Output size:  torch.Size([64, 8])\n","Test if batch is balanced: \n","dict_keys([1, 3, 7, 5, 4, 6, 0, 2])\n","dict_values([6, 10, 10, 11, 8, 7, 7, 5])\n"]}],"source":["from collections import Counter\n","\n","for inputs, labels in train_dataloader:\n","  inputs = inputs.to(device)\n","  print(\"Input size:\", inputs.shape)\n","  out = model(inputs)\n","  print(\"Output size: \", out.shape)\n","\n","  labels = labels.tolist()\n","  print(\"Test if batch is balanced: \")\n","  print(Counter(labels).keys())\n","  print(Counter(labels).values())\n","  break"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPjYT4RgTSJ9LkiNgkZHDsf"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}