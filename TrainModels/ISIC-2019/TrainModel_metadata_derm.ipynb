{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOUXlzwwmxmhOMlvLCxa7z1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2LBzFFzm0xqf","executionInfo":{"status":"ok","timestamp":1694087687587,"user_tz":-180,"elapsed":33146,"user":{"displayName":"Θανάσης Πριμικύρης","userId":"14742434534342737133"}},"outputId":"0614e140-55b3-482a-abd7-4be4cdb3ee60"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import zipfile, os, urllib.request, glob, math, shutil, sys\n","import torchvision\n","import torch.optim as optim\n","from torchvision import datasets, models, transforms\n","from sklearn.metrics import confusion_matrix, balanced_accuracy_score, precision_recall_fscore_support, roc_auc_score, accuracy_score\n","import sklearn.metrics\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","import PIL\n","import PIL.Image\n","\n","sys.path.append('drive/MyDrive')\n","import modelArchs\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","resume = 0"]},{"cell_type":"markdown","source":["\n","\n","Οι εικόνες είναι αποθηκευμένες στο drive σε zip.\n","\n","Υπάρχουν 16 zip files, ένα για κάθε κλάση από το train και test dataset.\n","\n","Κάνω extract τις εικόνες.\n"],"metadata":{"id":"EB26Ji091KZK"}},{"cell_type":"code","source":["os.makedirs('train_imgs')\n","os.makedirs('val_imgs')\n","\n","prefix = 'drive/MyDrive/'\n","\n","for i in ['train_imgs', 'val_imgs']:\n","  for j in ['MEL','NV','BCC','AK','BKL','DF','VASC','SCC']:\n","\n","    name = i + '_' + j\n","    src_zip = prefix + name + '.zip'\n","    dest_zip = i + '/' + j\n","\n","    with zipfile.ZipFile(src_zip, 'r') as zip_ref:\n","      zip_ref.extractall(dest_zip)\n","\n","    print(\"Finished with: \", name)"],"metadata":{"id":"ps1roLEU1I2L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Κάνω load το μοντέλο που έγινε train χωρίς τα μετα-δεδομένα.Στη συνέχεια ορίζω το τελικό νευρωνικό δίκτυο που θα γίνει train στις εικόνες + μετα-δεδομένα."],"metadata":{"id":"L1n1u0KI1Qpi"}},{"cell_type":"code","source":["PATH = 'drive/MyDrive/mobilenet_sa_derm.pt'\n","pretrained_model = modelArchs.get_MobileNetSa(8,False)\n","pretrained_model.load_state_dict(torch.load(PATH)['model'])\n","\n","metaModel = modelArchs.get_metaModel_MobileNets(pretrained_model,11,8)\n","metaModel.to(device)"],"metadata":{"id":"Sm-YAWlD1PJM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load metadata."],"metadata":{"id":"hO0Ex6Zv1t1x"}},{"cell_type":"code","source":["train_dataset = pd.read_csv('drive/MyDrive/train_dataset_meta_derm.csv',converters={'sex': pd.eval, 'anatom_site_general': pd.eval, 'age_approx': pd.eval})\n","test_dataset = pd.read_csv('drive/MyDrive/val_dataset_meta_derm.csv',converters={'sex': pd.eval, 'anatom_site_general': pd.eval, 'age_approx': pd.eval})\n","print(len(train_dataset))\n","print(len(test_dataset))\n","train_dataset.head()"],"metadata":{"id":"IZrL25ZW1tik"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ορίζω διάφορα transformations για να κάνουμε augment το training set, ώστε να πετύχουμε καλύτερο generalization του μοντέλου."],"metadata":{"id":"jIgbvfKu2BoY"}},{"cell_type":"code","source":["transforms_train = transforms.Compose([\n","    transforms.RandomResizedCrop(size = 224, scale = (0.4,1.0)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomVerticalFlip(),\n","    transforms.ColorJitter(brightness = [0.7, 1.3], contrast = [0.7, 1.3], saturation = [0.7, 1.3], hue = [-0.1,0.1]),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","transforms_test = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])"],"metadata":{"id":"k-QZLMds2BI6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ορισμός υπερ-παραμέτρων."],"metadata":{"id":"DvNy5VHL2JXI"}},{"cell_type":"code","source":["epochs = 30\n","batch_len = 48\n","\n","criterion = nn.CrossEntropyLoss()\n","learning_rate = 0.001\n","optimizer = optim.Adam(metaModel.parameters(), lr=learning_rate)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma=0.2)\n","\n","if resume:\n","  checkpoint = torch.load('drive/MyDrive/mobilenet_sa_metadata_derm.pt')\n","  metaModel.load_state_dict(checkpoint['model'])\n","  optimizer.load_state_dict(checkpoint['optimizer'])\n","  scheduler.load_state_dict(checkpoint['scheduler'])\n","  epoch_count = checkpoint['epoch']\n","  print(scheduler.get_last_lr())\n","else:\n","  epoch_count = 1\n","\n","print(epoch_count)"],"metadata":{"id":"rDHJK2RE2Jwj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Υλοποιώ το δικό μου dataset, καθώς θα θέλαμε, εκτός από την εικόνα, να γίνονται load και τα αντίστοιχα metadata."],"metadata":{"id":"hsh8Pb8m2OO1"}},{"cell_type":"code","source":["features_list = ['age_approx', 'anatom_site_general', 'sex']\n","\n","class ImageFolderWithFileNames(datasets.ImageFolder):\n","\n","    def __init__(self, root_dir, train_transformations, current_dataset, features_list):\n","\n","      super().__init__(root_dir,train_transformations)\n","\n","      self.current_dataset = current_dataset\n","      self.features_list = features_list\n","\n","    def __getitem__(self, index):\n","\n","      path, target = self.imgs[index]\n","\n","      filename = path[path.rfind('/') + 1:]\n","      metadata_features = self.get_metadata_features(filename)\n","\n","      img = self.loader(path)\n","      if self.transform is not None:\n","        img = self.transform(img)\n","      if self.target_transform is not None:\n","        target = self.target_transform(target)\n","\n","      return metadata_features,img,target\n","\n","    def get_metadata_features(self,filename):\n","\n","      features = []\n","\n","      index_row = self.current_dataset.index[self.current_dataset['image'] == filename[:-4]].tolist()[0]#get index of the row that corresponds to the image\n","\n","      feature_cols = self.current_dataset.iloc[index_row][self.features_list].to_numpy().flatten()\n","\n","      for i in feature_cols:\n","        for j in list(i):\n","          features.append(j)\n","\n","      return torch.tensor(features)"],"metadata":{"id":"jAt1_22X2Mjw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ορίζουμε weights για κάθε κλάση, ώστε να αντιμετωπίσουμε το πρόβλημα του imbalanced dataset."],"metadata":{"id":"t3H7xtt63T8I"}},{"cell_type":"code","source":["def get_weights_for_imgs(images, n_categories):\n","\n","    n_images = len(images)\n","\n","    imgs_per_category = [0] * n_categories\n","    for _, image_category in images:\n","      imgs_per_category[image_category] += 1\n","\n","    weight_per_category = [0] * n_categories # έχουμε 8 κατηγορίες\n","    for i in range(n_categories):\n","      weight_per_category[i] = 1 / float(imgs_per_category[i])#float(n_images) / float(imgs_per_category[i])\n","\n","    weights = [0] * n_images\n","    for idx, (_, image_category) in enumerate(images):\n","        weights[idx] = weight_per_category[image_category]\n","\n","    return weights\n","\n","train_dataset_imgs = ImageFolderWithFileNames('train_imgs', transforms_train, train_dataset, features_list)\n","test_dataset_imgs = ImageFolderWithFileNames('val_imgs', transforms_test, test_dataset, features_list)\n","\n","len_train_dataset_imgs = len(train_dataset_imgs)\n","len_test_dataset_imgs = len(test_dataset_imgs)\n","\n","print(\"Length of train_dataset: \", len_train_dataset_imgs)\n","print(\"Length of test dataset: \", len_test_dataset_imgs)\n","\n","weights = get_weights_for_imgs(train_dataset_imgs.imgs, len(train_dataset_imgs.classes))\n","weights = torch.DoubleTensor(weights)\n","train_sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))\n","\n","train_dataloader_imgs = torch.utils.data.DataLoader(train_dataset_imgs, batch_size = batch_len, sampler = train_sampler, pin_memory=True)\n","test_dataloader_imgs = torch.utils.data.DataLoader(test_dataset_imgs, batch_size = 16, shuffle=False)"],"metadata":{"id":"XHIfcCIt3UOc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ορίζω συναρτήσεις για υπολογισμό του accuracy και του confusion matrix πάνω στο test set. Στη συνέχεια θα δημιουργήσω και άλλες συναρτήσεις για υπολογισμό F1-score, sensitivity, specificity, precision."],"metadata":{"id":"howtmYp935E8"}},{"cell_type":"code","source":["def test_model(model,test_dataloader):\n","\n","  test_acc = 0.0\n","  pred_list = []\n","  label_list = []\n","  output_probs = []\n","  metrics = []\n","\n","  for i, (metadata_features, imgs, labels) in enumerate(test_dataloader,1):\n","\n","    label_list.extend(labels.data.tolist())\n","\n","    metadata_features = metadata_features.to(device)\n","    imgs = imgs.to(device)\n","    labels = labels.to(device)\n","\n","    outputs = model(metadata_features,imgs)\n","\n","    probs = torch.softmax(outputs.data.cpu(), dim = 1).tolist()\n","    output_probs.extend(probs)\n","\n","    pred =  torch.max(outputs, 1)[1].data.cpu().tolist()\n","    pred_list.extend(pred)\n","\n","  conf_matrix = confusion_matrix(label_list , pred_list)\n","\n","  metrics.append(accuracy_score(label_list, pred_list))\n","  metrics.extend(precision_recall_fscore_support(label_list,pred_list, average = 'macro'))\n","  metrics.append(roc_auc_score(label_list,output_probs, average = 'macro', multi_class = 'ovr'))\n","  metrics.extend(precision_recall_fscore_support(label_list,pred_list, average = 'weighted'))\n","  metrics.append(roc_auc_score(label_list,output_probs, average = 'weighted', multi_class = 'ovr'))\n","\n","  return metrics, conf_matrix"],"metadata":{"id":"YpzEMjuA35rE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Το βασικό train loop."],"metadata":{"id":"vF3BpoRg4E4W"}},{"cell_type":"code","source":["for epoch in range(epoch_count, epochs + 1):\n","\n","  metaModel.train()\n","\n","  train_running_loss = 0\n","\n","  #Training phase\n","  print(\"Starting epoch: \" , epoch)\n","\n","  for i, (metadata_features, imgs, labels) in enumerate(train_dataloader_imgs,1):\n","\n","      metadata_features = metadata_features.to(device)\n","      imgs = imgs.to(device)\n","      labels = labels.to(device)\n","\n","      optimizer.zero_grad()\n","      outputs = metaModel(metadata_features,imgs)\n","      loss = criterion(outputs, labels)\n","      loss.backward()\n","      optimizer.step()\n","\n","      train_running_loss += loss.detach().item()\n","\n","  print('Epoch: %d | Loss: %.4f ' %(epoch, train_running_loss / i))\n","  scheduler.step()\n","\n","  metaModel.eval()\n","\n","  try:\n","    metrics,conf_matrix = test_model(metaModel,test_dataloader_imgs)\n","    print('Test metrics on epoch %d:' %(epoch))\n","    print(metrics)\n","    print(\"Confusion matrix: \")\n","    print(conf_matrix)\n","  except:\n","    print(\"Error in calculating metrics\")\n","\n","  try:\n","    checkpoint = {'epoch': epoch+1, 'model': metaModel.state_dict(), 'optimizer': optimizer.state_dict(), 'scheduler': scheduler.state_dict()}\n","    checkpoint_fn = 'drive/MyDrive/checkpoint' + str(epoch) + '.pt'\n","    torch.save(checkpoint, checkpoint_fn)\n","  except:\n","    print(\"Error in writing general checkpoint\")\n","  if epoch - epoch_count >= 5:\n","    break"],"metadata":{"id":"h6Jhe9mN4FKp"},"execution_count":null,"outputs":[]}]}